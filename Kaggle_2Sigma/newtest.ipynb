{"cells":[{"metadata":{"trusted":true,"_uuid":"95a5bfd638c9824676f5f8cc480e7f12c07555a6","_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport datetime\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport re\nfrom scipy import stats\n\nmatplotlib.rcParams['figure.figsize'] = (10, 5)\nmatplotlib.rcParams['font.size'] = 12\n\nimport random\nrandom.seed(1)\nimport time\n\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import get_scorer\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import VotingClassifier\nimport lightgbm as lgb\nfrom sklearn.externals.joblib import Parallel, delayed\nfrom sklearn.base import clone\n\nimport pickle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c20d167ff505b4e4e713539167f0afca20a3e70a"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from kaggle.competitions import twosigmanews\n# You can only call make_env() once, so don't lose it!\nenv = twosigmanews.make_env()\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3159e3be827a2d2b71aa3e7239db721b2a4d46bf","_kg_hide-input":true},"cell_type":"code","source":"(market_train_orig, news_train_orig) = env.get_training_data()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"f5326503524aad22fab6bf8492f89b2f8f050d48"},"cell_type":"code","source":"market_train_orig = market_train_orig.sort_values('time')\nnews_train_orig = news_train_orig.sort_values('time')\nmarket_train_df = market_train_orig.copy()\nnews_train_df = news_train_orig.copy()\ndel market_train_orig\ndel news_train_orig","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a07d4edb39df2b8a342cb10464089e98f3d6e866"},"cell_type":"code","source":"market_train_df = market_train_df.loc[market_train_df['time'].dt.date>=datetime.date(2010,1,1)]\nnews_train_df = news_train_df.loc[news_train_df['time'].dt.date>=datetime.date(2010,1,1)]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"68466b551f475190c8eefd24efc8609b32921ce9"},"cell_type":"code","source":"market_train_df['close_open_ratio'] = np.abs(market_train_df['close']/market_train_df['open'])\nthreshold = 0.5\nprint('In %i lines price increases by 50%% or more in a day' %(market_train_df['close_open_ratio']>=1.5).sum())\nprint('In %i lines price decreases by 50%% or more in a day' %(market_train_df['close_open_ratio']<=0.5).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"461e324fda87ccf91650719a5772b8250f0caca4"},"cell_type":"code","source":"market_train_df = market_train_df.loc[market_train_df['close_open_ratio'] < 1.5]\nmarket_train_df = market_train_df.loc[market_train_df['close_open_ratio'] > 0.5]\nmarket_train_df = market_train_df.drop(columns=['close_open_ratio'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"ef83838cb75cbeb2e1bca6415ad6a65a6c1d11a1"},"cell_type":"code","source":"column_market = ['returnsClosePrevMktres1','returnsOpenPrevMktres1','returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\ncolumn_raw = ['returnsClosePrevRaw1', 'returnsOpenPrevRaw1','returnsClosePrevRaw10', 'returnsOpenPrevRaw10']\nfor i in range(len(column_raw)):\n    market_train_df[column_market[i]] = market_train_df[column_market[i]].fillna(market_train_df[column_raw[i]])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"3123f881db9827e614d29cb8ce40a688fe0abf76"},"cell_type":"code","source":"print('Removing outliers ...')\ncolumn_return = column_market + column_raw + ['returnsOpenNextMktres10']\norig_len = market_train_df.shape[0]\nfor column in column_return:\n    market_train_df = market_train_df.loc[market_train_df[column]>=-2]\n    market_train_df = market_train_df.loc[market_train_df[column]<=2]\nnew_len = market_train_df.shape[0]\nrmv_len = np.abs(orig_len-new_len)\nprint('There were %i lines removed' %rmv_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a86c7c17afb7ab3de2a051c8aae005bc7c0d3c9c"},"cell_type":"code","source":"print('Removing strange data ...')\norig_len = market_train_df.shape[0]\nmarket_train_df = market_train_df[~market_train_df['assetCode'].isin(['PGN.N','EBRYY.OB'])]\n#market_train_df = market_train_df[~market_train_df['assetName'].isin(['Unknown'])]\nnew_len = market_train_df.shape[0]\nrmv_len = np.abs(orig_len-new_len)\nprint('There were %i lines removed' %rmv_len)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"f0b7ff853e590f8fd2d3d36a65f0953ec892a025"},"cell_type":"code","source":"# Function to remove outliers\ndef remove_outliers(data_frame, column_list, low=0.02, high=0.98):\n    for column in column_list:\n        this_column = data_frame[column]\n        quant_df = this_column.quantile([low,high])\n        low_limit = quant_df[low]\n        high_limit = quant_df[high]\n        data_frame[column] = data_frame[column].clip(lower=low_limit, upper=high_limit)\n    return data_frame","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"659a7d37420c018f7349a9eea9b8537441243ad6"},"cell_type":"code","source":"# Remove outlier\ncolumns_outlier = ['takeSequence', 'bodySize', 'sentenceCount', 'wordCount', 'sentimentWordCount', 'firstMentionSentence','noveltyCount12H',\\\n                  'noveltyCount24H', 'noveltyCount3D', 'noveltyCount5D', 'noveltyCount7D', 'volumeCounts12H', 'volumeCounts24H',\\\n                  'volumeCounts3D','volumeCounts5D','volumeCounts7D']\nprint('Clipping news outliers ...')\nnews_train_df = remove_outliers(news_train_df, columns_outlier)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7acf780c5abc2c5da49bbed1fd72de913b0bbd60"},"cell_type":"code","source":"asset_code_dict = {k: v for v, k in enumerate(market_train_df['assetCode'].unique())}\ndrop_columns = [col for col in news_train_df.columns if col not in ['sourceTimestamp', 'urgency', 'takeSequence', 'bodySize', 'companyCount', \n               'sentenceCount', 'firstMentionSentence', 'relevance','firstCreated', 'assetCodes']]\ncolumns_news = ['firstCreated','relevance','sentimentClass','sentimentNegative','sentimentNeutral',\n               'sentimentPositive','noveltyCount24H','noveltyCount7D','volumeCounts24H','volumeCounts7D','assetCodes','sourceTimestamp',\n               'assetName','audiences', 'urgency', 'takeSequence', 'bodySize', 'companyCount', \n               'sentenceCount', 'firstMentionSentence','time']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"97faaaebe99bea04efc745693d38b966cf879c1e"},"cell_type":"code","source":"# Data processing function\ndef data_prep(market_df,news_df):\n    market_df['date'] = market_df.time.dt.date\n    market_df['close_to_open'] = market_df['close'] / market_df['open']\n    market_df.drop(['time'], axis=1, inplace=True)\n    \n    news_df = news_df[columns_news]\n    news_df['sourceTimestamp']= news_df.sourceTimestamp.dt.hour\n    news_df['firstCreated'] = news_df.firstCreated.dt.date\n    news_df['assetCodesLen'] = news_df['assetCodes'].map(lambda x: len(eval(x)))\n    news_df['assetCodes'] = news_df['assetCodes'].map(lambda x: list(eval(x))[0])\n    news_df['asset_sentiment_count'] = news_df.groupby(['assetName', 'sentimentClass'])['time'].transform('count')\n    news_df['len_audiences'] = news_train_df['audiences'].map(lambda x: len(eval(x)))\n    kcol = ['firstCreated', 'assetCodes']\n    news_df = news_df.groupby(kcol, as_index=False).mean()\n    market_df = pd.merge(market_df, news_df, how='left', left_on=['date', 'assetCode'], \n                            right_on=['firstCreated', 'assetCodes'])\n    del news_df\n    market_df['assetCodeT'] = market_df['assetCode'].map(asset_code_dict)\n    market_df = market_df.drop(columns = ['firstCreated','assetCodes','assetName']).fillna(0) \n    return market_df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"22c089c414023040b4b17a8517d21eb24f025833"},"cell_type":"code","source":"print('Merging data ...')\nmarket_train_df = data_prep(market_train_df, news_train_df)\nmarket_train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"9c43ae5ecdda576dbc908ee4afe7a8adf61ab10a"},"cell_type":"code","source":"market_train_df = market_train_df.loc[market_train_df['date']>=datetime.date(2010,1,1)]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"bb2f32a2f104f05eeb0fe274587be846533dd059"},"cell_type":"code","source":"num_columns = ['volume', 'close', 'open', 'returnsClosePrevRaw1', 'returnsOpenPrevRaw1', 'returnsClosePrevMktres1', 'returnsOpenPrevMktres1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10', \n               'returnsClosePrevMktres10', 'returnsOpenPrevMktres10', 'close_to_open', 'sourceTimestamp', 'urgency', 'companyCount', 'takeSequence', 'bodySize', 'sentenceCount',\n               'relevance', 'sentimentClass', 'sentimentNegative', 'sentimentNeutral', 'sentimentPositive',\n               'noveltyCount24H','noveltyCount7D','volumeCounts24H','volumeCounts7D','assetCodesLen', 'asset_sentiment_count', 'len_audiences']\ncat_columns = ['assetCodeT']\nfeature_columns = num_columns+cat_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"804b093a309dcc6f993f2158a15aaa40d646005f"},"cell_type":"code","source":"# Scaling of data\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\ndata_scaler = StandardScaler()\n#market_train_df[num_columns] = data_scaler.fit_transform(market_train_df[num_columns])\n#data_scaler = MinMaxScaler()\nmarket_train_df[num_columns] = data_scaler.fit_transform(market_train_df[num_columns])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"cbf8c289fd90dcd07e1b51b5c418f4a9c518f865"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nmarket_train_df = market_train_df.reset_index()\nmarket_train_df = market_train_df.drop(columns='index')\n\n# Random train-test split\ntrain_indices, val_indices = train_test_split(market_train_df.index.values,test_size=0.1, random_state=92)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9cd7c56481fbbd403506e7ca0e851006905463c"},"cell_type":"code","source":"# Extract X and Y\ndef get_input(market_train, indices):\n    X = market_train.loc[indices, feature_columns].values\n    y = market_train.loc[indices,'returnsOpenNextMktres10'].map(lambda x: 0 if x<0 else 1).values\n    #y = market_train.loc[indices,'returnsOpenNextMktres10'].map(lambda x: convert_to_class(x)).values\n    r = market_train.loc[indices,'returnsOpenNextMktres10'].values\n    u = market_train.loc[indices, 'universe']\n    d = market_train.loc[indices, 'date']\n    return X,y,r,u,d\n\n# r, u and d are used to calculate the scoring metric\nX_train,y_train,r_train,u_train,d_train = get_input(market_train_df, train_indices)\nX_val,y_val,r_val,u_val,d_val = get_input(market_train_df, val_indices)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"11a7aabb57359d9e352ba60fe5b71c3b10c5e21c"},"cell_type":"code","source":"# Set up decay learning rate\ndef learning_rate_power(current_round):\n    base_learning_rate = 0.19000424246380565\n    min_learning_rate = 0.01\n    lr = base_learning_rate * np.power(0.995,current_round)\n    return max(lr, min_learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b07f8ae59788b650dd3a580baf06e6825d802e66"},"cell_type":"code","source":"from scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\n\ntune_params = {'n_estimators': [200,500,1000,2500,5000],\n              'max_depth': sp_randint(4,12),\n              'colsample_bytree':sp_uniform(loc=0.8, scale=0.15),\n              'min_child_samples':sp_randint(60,120),\n              'subsample': sp_uniform(loc=0.75, scale=0.25),\n              'reg_lambda':[1e-3, 1e-2, 1e-1, 1]}\n\nfit_params = {'early_stopping_rounds':10,\n              'eval_metric': 'accuracy',\n              'eval_set': [(X_train, y_train), (X_val, y_val)],\n              'verbose': 20,\n              'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_power)]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a01d9dd5c8aec006d56b1201fee4dc31e4f73d9"},"cell_type":"code","source":"lgb_clf = lgb.LGBMClassifier(n_jobs=4, objective='binary',random_state=1)\ngs = RandomizedSearchCV(estimator=lgb_clf, \n                        param_distributions=tune_params, \n                        n_iter=40,\n                        scoring='f1',\n                        cv=5,\n                        refit=True,\n                        random_state=1,\n                        verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e8cf0735a82efde76dc8f5ea222ca1fc1ebf5ab"},"cell_type":"code","source":"lgb_clf = lgb.LGBMClassifier(n_jobs=4,\n                             objective='multiclass',\n                            random_state=100)\nopt_params = {'n_estimators':500,\n              'boosting_type': 'dart',\n              'objective': 'binary',\n              'num_leaves':2452,\n              'min_child_samples':212,\n              'reg_lambda':0.01}\nlgb_clf.set_params(**opt_params)\nlgb_clf.fit(X_train, y_train,**fit_params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8645f1f4155e13a14bc9ef857ae7c2853421322c","_kg_hide-input":true},"cell_type":"code","source":"print('Training accuracy: ', accuracy_score(y_train, lgb_clf.predict(X_train)))\nprint('Validation accuracy: ', accuracy_score(y_val, lgb_clf.predict(X_val)))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"79a41d0e7126c8c31fc1e71cd9f486147b264f37"},"cell_type":"code","source":"features_imp = pd.DataFrame()\nfeatures_imp['features'] = list(feature_columns)[:]\nfeatures_imp['importance'] = lgb_clf.feature_importances_\nfeatures_imp = features_imp.sort_values(by='importance', ascending=False).reset_index()\n\ny_plot = -np.arange(15)\nplt.figure(figsize=(10,6))\nplt.barh(y_plot, features_imp.loc[:14,'importance'].values)\nplt.yticks(y_plot,(features_imp.loc[:14,'features']))\nplt.xlabel('Feature importance')\nplt.title('Features importance')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"1ab512bd883ea909f4901d54a7ead9bfe298eae6"},"cell_type":"code","source":"# Rescale confidence\ndef rescale(data_in, data_ref):\n    scaler_ref =  StandardScaler()\n    scaler_ref.fit(data_ref.reshape(-1,1))\n    scaler_in = StandardScaler()\n    data_in = scaler_in.fit_transform(data_in.reshape(-1,1))\n    data_in = scaler_ref.inverse_transform(data_in)[:,0]\n    return data_in","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"3f02912a526528c04cb8d33e08bee6f7df5c16e9"},"cell_type":"code","source":"def confidence_out(y_pred):\n    confidence = np.zeros(y_pred.shape[0])\n    for i in range(len(confidence)):\n        if y_pred[i,:].argmax() != 1:\n            confidence[i] = y_pred[i,2]-y_pred[i,0]\n    return confidence","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0039f3cbc0393c10633399116ab29dfead00bfa1"},"cell_type":"code","source":"y_pred_proba = lgb_clf.predict_proba(X_val)\npredicted_return = y_pred_proba[:,1] - y_pred_proba[:,0]\n#predicted_return = confidence_out(y_pred_proba)\npredicted_return = rescale(predicted_return, r_train)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"4594fd71ba2eb30775aa219bb4f32555bd2f1290"},"cell_type":"code","source":"# distribution of confidence that will be used as submission\nplt.hist(predicted_return, bins='auto', label='Predicted confidence')\nplt.hist(r_val, bins='auto',alpha=0.8, label='True market return')\nplt.title(\"predicted confidence\")\nplt.legend(loc='best')\nplt.xlim(-1,1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0ead35ca766d8fed0d5de6dc798051ed0cda387b"},"cell_type":"code","source":"# calculation of actual metric that is used to calculate final score\nr_val = r_val.clip(-1,1) # get rid of outliers.\nx_t_i = predicted_return * r_val * u_val\ndata = {'day' : d_val, 'x_t_i' : x_t_i}\ndf = pd.DataFrame(data)\nx_t = df.groupby('day').sum().values.flatten()\nmean = np.mean(x_t)\nstd = np.std(x_t)\nscore_valid = mean / std\nprint('Validation score', score_valid)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"b3349437a5eddb48dc4aaed2b0303a744f7147a2"},"cell_type":"code","source":"# This code is inspired from this kernel: https://www.kaggle.com/skooch/lgbm-w-random-split-2\nclfs = []\nfor i in range(20):\n    clf = lgb.LGBMClassifier(learning_rate=0.1, random_state=1200+i, silent=True,\n                             n_jobs=4, n_estimators=2500)\n    clf.set_params(**opt_params)\n    clfs.append(('lgbm%i'%i, clf))\n\ndef split_data(X, y, test_percentage=0.2, seed=None):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_percentage)\n    return X_train, y_train, X_test, y_test \n\ndef _parallel_fit_estimator(estimator, X, y, sample_weight=None, **fit_params):\n    \n    # randomly split the data so we have a test set for early stopping\n    X_train, y_train, X_test, y_test = split_data(X, y, seed=1992)\n    \n    # update the fit params with our new split\n    fit_params[\"eval_set\"] = [(X_train,y_train), (X_test,y_test)]\n    \n    # fit the estimator\n    if sample_weight is not None:\n        estimator.fit(X_train, y_train, sample_weight=sample_weight, **fit_params)\n    else:\n        estimator.fit(X_train, y_train, **fit_params)\n    return estimator","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0e0f7a3f920055675759fb243c9afda8baa57658"},"cell_type":"code","source":"class VotingClassifierLGBM(VotingClassifier):\n    '''\n    This implements the fit method of the VotingClassifier propagating fit_params\n    '''\n    def fit(self, X, y, sample_weight=None, **fit_params):\n        \n        if isinstance(y, np.ndarray) and len(y.shape) > 1 and y.shape[1] > 1:\n            raise NotImplementedError('Multilabel and multi-output'\n                                      ' classification is not supported.')\n\n        if self.voting not in ('soft', 'hard'):\n            raise ValueError(\"Voting must be 'soft' or 'hard'; got (voting=%r)\"\n                             % self.voting)\n\n        if self.estimators is None or len(self.estimators) == 0:\n            raise AttributeError('Invalid `estimators` attribute, `estimators`'\n                                 ' should be a list of (string, estimator)'\n                                 ' tuples')\n\n        if (self.weights is not None and\n                len(self.weights) != len(self.estimators)):\n            raise ValueError('Number of classifiers and weights must be equal'\n                             '; got %d weights, %d estimators'\n                             % (len(self.weights), len(self.estimators)))\n\n        if sample_weight is not None:\n            for name, step in self.estimators:\n                if not has_fit_parameter(step, 'sample_weight'):\n                    raise ValueError('Underlying estimator \\'%s\\' does not'\n                                     ' support sample weights.' % name)\n        names, clfs = zip(*self.estimators)\n        self._validate_names(names)\n\n        n_isnone = np.sum([clf is None for _, clf in self.estimators])\n        if n_isnone == len(self.estimators):\n            raise ValueError('All estimators are None. At least one is '\n                             'required to be a classifier!')\n\n        self.le_ = LabelEncoder().fit(y)\n        self.classes_ = self.le_.classes_\n        self.estimators_ = []\n\n        transformed_y = self.le_.transform(y)\n\n        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n                delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n                                                 sample_weight=sample_weight, **fit_params)\n                for clf in clfs if clf is not None)\n\n        return self","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4250806eef11526dea2c75ba6c7646151b5ed89a"},"cell_type":"code","source":"vc = VotingClassifierLGBM(clfs, voting='soft')\nvc.fit(X_train, y_train, **fit_params)\nfilename = 'VotingClassifierLGBM.sav'\npickle.dump(vc, open(filename, 'wb'))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"937291f6fb46376eb3c2ba9b6af22747712d3de4"},"cell_type":"code","source":"vc = pickle.load(open(filename, 'rb'))\nvc.voting = 'soft'\npredicted_class = vc.predict(X_val)\npredicted_return = vc.predict_proba(X_val)\n#predicted_return = confidence_out(predicted_return)\npredicted_return = vc.predict_proba(X_val)[:,1]*2-1\npredicted_return = rescale(predicted_return, r_train)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"acb35559e7d2397d6171a868ac4bbba0193f52fb"},"cell_type":"code","source":"plt.hist(predicted_class, bins='auto')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"1b1d3be6e63555feb2d3e7534171e5a5f7e1023c"},"cell_type":"code","source":"vc.voting = 'soft'\nglobal_accuracy_soft = accuracy_score(y_val, predicted_class)\nglobal_f1_soft = f1_score(y_val, predicted_class)\nprint('Accuracy score clfs: %f' % global_accuracy_soft)\nprint('F1 score clfs: %f' % global_f1_soft)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"6900a1f6173704a54c8470d3b6c46e539170232d"},"cell_type":"code","source":"# distribution of confidence that will be used as submission\nplt.hist(predicted_return, bins='auto', label='Prediciton')\nplt.hist(r_val, bins='auto',alpha=0.8, label='True data')\nplt.title(\"predicted confidence\")\nplt.legend(loc='best')\nplt.xlim(-1,1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"ae65c3ff019cc6450beb18b0770d1200ba7faf77"},"cell_type":"code","source":"# calculation of actual metric that is used to calculate final score\nr_val = r_val.clip(-1,1) # get rid of outliers. Where do they come from??\nx_t_i = predicted_return * r_val * u_val\ndata = {'day' : d_val, 'x_t_i' : x_t_i}\ndf = pd.DataFrame(data)\nx_t = df.groupby('day').sum().values.flatten()\nmean = np.mean(x_t)\nstd = np.std(x_t)\nscore_valid = mean / std\nprint('Validation score', score_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0df941edebf61d488a11e8c6b00bc13d05e300b6"},"cell_type":"code","source":"days = env.get_prediction_days()\nn_days = 0\nprep_time = 0\nprediction_time = 0\npackaging_time = 0\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    n_days +=1\n    if n_days % 50 == 0:\n        print(n_days,end=' ')\n\n    t = time.time()\n    column_market = ['returnsClosePrevMktres1','returnsOpenPrevMktres1','returnsClosePrevMktres10', 'returnsOpenPrevMktres10']\n    column_raw = ['returnsClosePrevRaw1', 'returnsOpenPrevRaw1','returnsClosePrevRaw10', 'returnsOpenPrevRaw10']\n    market_obs_df['close_open_ratio'] = np.abs(market_obs_df['close']/market_obs_df['open'])\n    for i in range(len(column_raw)):\n        market_obs_df[column_market[i]] = market_obs_df[column_market[i]].fillna(market_obs_df[column_raw[i]])\n\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n    market_obs_df = market_obs_df[market_obs_df.assetCode.isin(asset_code_dict.keys())]\n    market_obs = data_prep(market_obs_df, news_obs_df)\n    market_obs[num_columns] = data_scaler.transform(market_obs[num_columns])\n    X_live = market_obs[feature_columns].values\n    prep_time += time.time() - t\n\n    t = time.time()\n    lp = vc.predict_proba(X_live)\n    prediction_time += time.time() -t\n\n    t = time.time()\n    confidence = lp[:,1] - lp[:,0]\n    #confidence = confidence_out(lp)\n    confidence = rescale(confidence, r_train)\n    preds = pd.DataFrame({'assetCode':market_obs['assetCode'],'confidence':confidence})\n    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n    env.predict(predictions_template_df)\n    packaging_time += time.time() - t\n\nenv.write_submission_file()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}